{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import torch from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "# Load pre-trained GPT-2 model and tokenizer\n",
    "\n",
    "model_name = “gpt2-medium” \\# You can use other sizes like “gpt2”,\n",
    "“gpt2-large”, etc. model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# Generate text using the pre-trained model\n",
    "\n",
    "def generate_text(prompt, max_length=100, temperature=0.7): input_ids =\n",
    "tokenizer.encode(prompt, return_tensors=“pt”)\n",
    "\n",
    "    # Generate text using the model\n",
    "    output = model.generate(input_ids, max_length=max_length, temperature=temperature)\n",
    "\n",
    "    generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    return generated_text\n",
    "\n",
    "# Generate text based on a prompt\n",
    "\n",
    "prompt = “Once upon a time” generated_text = generate_text(prompt,\n",
    "max_length=200, temperature=0.7) print(generated_text)"
   ],
   "id": "42a14256-91c8-446e-92a7-ab6bf11055d3"
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {}
}
